# Computational Neuroscience

*   **Where:** Coursera
*   **University:** University of Washington
*   **Status:** In Progress
*   **Link:** https://www.coursera.org/learn/computational-neuroscience

# Week Progress

## Week 1: Introduction & Basic Neurobiology

*   **Status:** Completed
*   **Summary:** This module includes an Introduction to Computational Neuroscience, along with a primer on Basic Neurobiology.
*   **Notes:**
    *   [Lecture Note](W1/lecture_note.ipynb)

## Week 2: What do Neurons Encode? Neural Encoding Models

*   **Status:** Completed
*   **Summary:** This module introduces the world of neural information coding. You'll learn about the technologies used to record brain activity, develop mathematical formulations to characterize neuron spikes, and investigate variability and noise in the brain, and how models accommodate these factors.
*   **Notes:**
    *   [Lecture Note](W2/lecture_note.ipynb)
*  **Assignment:**
   *  [compute_sta.py](W2/compute_sta.py)
   *  [quiz2.py](W2/quiz2.py)

## Week 3: Extracting Information from Neurons: Neural Decoding

*   **Status:** Completed
*   **Summary:** This module focuses on neural decodingâ€”estimating what the brain is seeing, intending, or experiencing from neural activity. Applications include neuroprosthetics and brain-computer interfaces. A guest lecture by Fred Rieke, a notable computational neuroscientist, is included.
*   **Notes:**
    *   [Lecture Note](W3/lecture_note.ipynb)

## Week 4: Information Theory & Neural Coding

*   **Status:** Completed
*   **Summary:** This module explores the connections between information theory and neural coding. It will delve into how information theory principles apply to understanding brain function.
*   **Notes:**
    *   [Lecture Note](W4/lecture_note.ipynb)

## Week 5: Computing in Carbon

*   **Status:** Not Started
*   **Summary:** This module covers the biophysics of neurons, including the Hodgkin-Huxley model of action potential generation, other neuron models, and the modeling of neuronal structures like dendrites.
*   **Notes:**
    *   [Lecture Note](W5/lecture_note.ipynb)

## Week 6: Computing with Networks

*   **Status:** Not Started
*   **Summary:** This module explores neuronal network models, including synapses, integrate-and-fire neurons, firing rate models, feedforward networks, and recurrent networks. It will cover how these networks transform inputs to outputs and their dynamic interactions.
*   **Notes:**
    *   [Lecture Note](W6/lecture_note.ipynb)

## Week 7: Networks that Learn: Plasticity in the Brain & Learning

*   **Status:** Not Started
*   **Summary:** This module investigates synaptic plasticity and learning in the brain. Topics include Hebbian learning, unsupervised learning, sparse coding, and predictive coding.
*   **Notes:**
    *   [Lecture Note](W7/lecture_note.ipynb)

## Week 8: Learning from Supervision and Rewards

*   **Status:** Not Started
*   **Summary:** This module explores supervised learning and reinforcement learning. It covers supervised learning concepts, backpropagation, reinforcement learning techniques, reward prediction, and neural implementations in the basal ganglia, culminating in an application to fly a helicopter using reinforcement learning.
*   **Notes:**
    *   [Lecture Note](W8/lecture_note.ipynb)

## Certificates

*   **Computational Neuroscience**
    *   **Link:** \[URL to certificate, if available\]